# COVID-19 Chile: AnÃ¡lisis y Modelado Predictivo con Machine Learning

## DescripciÃ³n del Proyecto

Proyecto de anÃ¡lisis exhaustivo y modelado predictivo de datos COVID-19 en Chile (2020-2022) utilizando metodologÃ­as de Machine Learning y el framework Kedro. Implementa las primeras 3 fases de la metodologÃ­a CRISP-DM con orquestaciÃ³n en Airflow, versionado con DVC y despliegue en Docker para generar insights epidemiolÃ³gicos y capacidades predictivas reproducibles.

**Estudiantes:** Claudia MurÃºa - [Nombre Estudiante 2]  
**Curso:** MLY0100 - Machine Learning  
**InstituciÃ³n:** [Tu Universidad]  
**Fecha:** Octubre 2025

---

## ğŸ¯ Objetivos

### Objetivos de Negocio
- Analizar la evoluciÃ³n temporal de la pandemia COVID-19 en Chile
- Identificar patrones geogrÃ¡ficos y diferencias regionales
- Caracterizar olas pandÃ©micas y perÃ­odos crÃ­ticos
- Evaluar indicadores epidemiolÃ³gicos clave
- Generar insights para optimizaciÃ³n de polÃ­ticas sanitarias

### Objetivos de Machine Learning
- Desarrollar modelos predictivos para casos futuros a corto plazo (7-14 dÃ­as)
- Crear sistema de clasificaciÃ³n de perÃ­odos de alta/baja transmisiÃ³n
- Implementar detecciÃ³n automÃ¡tica de tendencias epidemiolÃ³gicas
- Modelar volatilidad y riesgo de saturaciÃ³n hospitalaria
- Optimizar feature engineering para mÃ¡ximo poder predictivo

---

## ğŸ“Š Datasets

El proyecto utiliza 3 datasets principales de COVID-19 Chile:

| Dataset | PerÃ­odo | Registros | DescripciÃ³n |
|---------|---------|-----------|-------------|
| chile_completo_covid_2020.csv | 2020 | 33,253 | Datos COVID-19 Chile aÃ±o 2020 |
| chile_completo_covid_2021.csv | 2021 | 36,330 | Datos COVID-19 Chile aÃ±o 2021 |
| chile_completo_covid_2022.csv | 2022 | 29,610 | Datos COVID-19 Chile aÃ±o 2022 |

**Total:** 99,193 registros de 363 ubicaciones Ãºnicas cubriendo el perÃ­odo 2020-2022

---

## ğŸ—ï¸ Arquitectura del Proyecto

### Stack TecnolÃ³gico
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Apache Airflow (OrquestaciÃ³n)            â”‚
â”‚                    http://localhost:8080                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Kedro Pipelines (Procesamiento ML)             â”‚
â”‚  data_processing â†’ data_science â†’ reporting                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 DVC (Versionado de Datos)                   â”‚
â”‚  Datasets + Modelos + MÃ©tricas + Visualizaciones            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Docker (Contenedores)                      â”‚
â”‚  Ambiente aislado y reproducible                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MetodologÃ­a CRISP-DM

#### Fase 1: Business Understanding - âœ… Completada
- DefiniciÃ³n del problema de negocio
- Objetivos especÃ­ficos y criterios de Ã©xito
- EvaluaciÃ³n de recursos y riesgos
- Plan detallado del proyecto

#### Fase 2: Data Understanding - âœ… Completada
- EDA exhaustivo (univariado, bivariado, multivariado)
- AnÃ¡lisis de calidad de datos
- IdentificaciÃ³n de patrones temporales y geogrÃ¡ficos
- ValidaciÃ³n de integridad de datos

#### Fase 3: Data Preparation - âœ… Completada
- Limpieza diferenciada por dataset
- Feature engineering avanzado
- IntegraciÃ³n de mÃºltiples fuentes
- PreparaciÃ³n de targets para ML

### Pipelines Kedro

| Pipeline | DescripciÃ³n | Nodos | Funcionalidad |
|----------|-------------|-------|---------------|
| data_processing (dp) | Feature engineering avanzado | 6 | CreaciÃ³n de 80+ variables predictivas |
| data_science (ds) | Entrenamiento y evaluaciÃ³n | 7 | Modelado de 51 modelos ML con GridSearchCV |
| reporting (rp) | VisualizaciÃ³n y reportes | 4 | GeneraciÃ³n de insights y grÃ¡ficos |

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- **Python 3.8+** (recomendado 3.11)
- **Git** para control de versiones
- **Docker Desktop (con WSL 2):** Esencial para Airflow
- **8GB RAM** recomendado para procesamiento
- **5GB espacio libre** en disco

### ConfiguraciÃ³n de Memoria de WSL 2 (Windows)

âš ï¸ **IMPORTANTE:** Si usas WSL 2, aumenta la memoria asignada editando `.wslconfig` en `C:\Users\<TuUsuario>\`:
```ini
[wsl2]
memory=8GB   
processors=4
```

Luego ejecuta en PowerShell (admin):
```powershell
wsl --shutdown
```

Y reinicia Docker Desktop.

### InstalaciÃ³n

1. **Clonar el repositorio:**
```bash
git clone https://github.com/ClauMurua/data_covid_ML.git
cd data_covid_ML/spaceflights
```

2. **Crear ambiente virtual:**
```bash
python -m venv kedro-env
source kedro-env/bin/activate  # Linux/Mac
kedro-env\Scripts\activate     # Windows
```

3. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

4. **Configurar DVC:**
```bash
dvc pull  # Descargar datos versionados
```

5. **Configurar estructura de datos:**
```bash
mkdir -p data/01_raw
# Los archivos CSV ya deberÃ­an estar despuÃ©s de dvc pull
```

---

## ğŸ”„ DVC - Versionado de Datos y Modelos

### âœ… Pipeline Configurado
```bash
CSV files â†’ data_processing â†’ data_science â†’ reporting
```

### Stages del Pipeline

#### 1. data_processing
- **Input:** 3 archivos CSV (Chile COVID 2020-2022)
- **Output:** regression_dataset.csv, classification_dataset.csv
- **PropÃ³sito:** Procesa datos crudos y crea 80+ features

#### 2. data_science
- **Input:** Datasets procesados
- **Output:** 
  - Modelos entrenados:
    - `trained_regression_models.pkl` (11MB)
    - `trained_classification_models.pkl` (137MB)
- **Metrics:** 
  - regression_metrics.json
  - classification_metrics.json
  - best_models_report.json
  - feature_importance_analysis.json
- **PropÃ³sito:** Entrena 51 modelos ML con GridSearchCV (k=5)

#### 3. reporting
- **Input:** MÃ©tricas JSON
- **Output:** 3 visualizaciones PNG (~920KB total)
  - regression_comparison.png
  - classification_comparison.png
  - summary_dashboard.png
- **Metrics:** tuning_summary.json
- **PropÃ³sito:** Genera reportes y grÃ¡ficos comparativos

### Archivos Versionados (148MB+ total)
```
data/
â”œâ”€â”€ 01_raw/
â”‚   â”œâ”€â”€ chile_completo_covid_2020.csv.dvc
â”‚   â”œâ”€â”€ chile_completo_covid_2021.csv.dvc
â”‚   â””â”€â”€ chile_completo_covid_2022.csv.dvc
â”œâ”€â”€ 06_models/
â”‚   â”œâ”€â”€ trained_regression_models.pkl (11MB)
â”‚   â””â”€â”€ trained_classification_models.pkl (137MB)
â”œâ”€â”€ 07_model_output/
â”‚   â”œâ”€â”€ regression_metrics.json
â”‚   â”œâ”€â”€ classification_metrics.json
â”‚   â”œâ”€â”€ best_models_report.json
â”‚   â””â”€â”€ feature_importance_analysis.json
â””â”€â”€ 08_reporting/
    â”œâ”€â”€ tuning_summary.json
    â”œâ”€â”€ regression_comparison.png
    â”œâ”€â”€ classification_comparison.png
    â””â”€â”€ summary_dashboard.png
```

### Comandos DVC
```bash
# Ver pipeline
dvc dag

# Ver estado
dvc status

# Reproducir todo el pipeline
dvc repro

# Ver mÃ©tricas
dvc metrics show

# Push/Pull de artefactos
dvc push
dvc pull
```

### Reproducibilidad con DVC

Para reproducir el proyecto completo desde cero:
```bash
# 1. Clonar repositorio
git clone https://github.com/ClauMurua/data_covid_ML.git
cd data_covid_ML/spaceflights

# 2. Pull de datos versionados
dvc pull

# 3. Reproducir pipeline
dvc repro
```

---

## âš™ï¸ EjecuciÃ³n del Proyecto

### OpciÃ³n 1: Pipelines Locales (Kedro)
```bash
# Ejecutar todos los pipelines
kedro run

# Ejecutar pipeline especÃ­fico
kedro run --pipeline=dp  # data_processing
kedro run --pipeline=ds  # data_science
kedro run --pipeline=rp  # reporting

# Ejecutar desde un nodo especÃ­fico
kedro run --from-nodes=train_regression_models

# Ejecutar hasta un nodo especÃ­fico
kedro run --to-nodes=prepare_modeling_data
```

### OpciÃ³n 2: OrquestaciÃ³n con Airflow (Docker)

#### Levantar el Entorno de Airflow
```bash
cd spaceflights
docker-compose -f docker-compose.airflow.yml up --build -d
```

- **Airflow UI:** `http://localhost:8080`
- **Usuario:** `admin`
- **ContraseÃ±a:** `admin`

#### Ejecutar el DAG

1. Abrir `http://localhost:8080`
2. Buscar DAG: `covid_ml_pipeline`
3. Activar y ejecutar (trigger manualmente o esperar schedule)

#### Monitorear EjecuciÃ³n
```bash
# Ver logs del scheduler
docker logs -f spaceflights-airflow-scheduler-1

# Ver logs del webserver
docker logs -f spaceflights-airflow-webserver-1

# Acceder al contenedor
docker exec -it spaceflights-airflow-scheduler-1 bash
```

#### Detener Airflow
```bash
docker-compose -f docker-compose.airflow.yml down
```

### OpciÃ³n 3: AnÃ¡lisis Interactivo
```bash
# Jupyter con contexto Kedro
kedro jupyter notebook

# VisualizaciÃ³n de pipelines
kedro viz
```

---

## ğŸ¤– Modelos de Machine Learning

### Targets Identificados

#### Problemas de RegresiÃ³n (6 targets):
1. `target_confirmed_next_7d_log` - PredicciÃ³n logarÃ­tmica de casos en 7 dÃ­as
2. `target_rolling_change_7d` - Cambio en casos (rolling 7 dÃ­as)
3. `target_growth_rate_next_14d` - Tasa de crecimiento en 14 dÃ­as
4. `target_risk_level` - Nivel de riesgo numÃ©rico
5. `target_trend_direction` - DirecciÃ³n de tendencia numÃ©rica
6. `target_change_pct_7d` - Cambio porcentual en 7 dÃ­as

#### Problemas de ClasificaciÃ³n (6 targets):
1. `target_confirmed_next_7d_log` - ClasificaciÃ³n de nivel de casos
2. `target_rolling_change_7d` - ClasificaciÃ³n de cambio
3. `target_growth_rate_next_14d` - ClasificaciÃ³n de crecimiento
4. `target_risk_level` - Nivel de riesgo categÃ³rico
5. `target_trend_direction` - DirecciÃ³n de tendencia
6. `target_high_transmission` - Alta/baja transmisiÃ³n

### Algoritmos Implementados

#### Modelos de RegresiÃ³n (5 algoritmos):
- Linear Regression
- Ridge Regression
- Lasso Regression
- Random Forest Regressor
- Gradient Boosting Regressor

**Total:** 30 modelos entrenados (6 targets Ã— 5 algoritmos)

#### Modelos de ClasificaciÃ³n (3-4 algoritmos):
- Logistic Regression
- Random Forest Classifier
- Gradient Boosting Classifier
- SVM (Support Vector Machine)

**Total:** 21 modelos entrenados

### HiperparÃ¡metros y Tuning

**MÃ©todo:** GridSearchCV con Cross-Validation (k=5 folds)

**ParÃ¡metros optimizados:**
- Random Forest: `n_estimators`, `max_depth`, `min_samples_split`
- Gradient Boosting: `learning_rate`, `n_estimators`, `max_depth`
- Ridge/Lasso: `alpha`
- Logistic Regression: `C`, `penalty`
- SVM: `C`, `kernel`, `gamma`

**Tiempo de entrenamiento total:** ~3 horas

### Resultados de Performance

#### RegresiÃ³n (mejores modelos por target):
- RÂ² promedio: **0.85 - 0.95**
- RMSE normalizado: **< 0.15**
- Mejor algoritmo: **Random Forest** y **Gradient Boosting**

#### ClasificaciÃ³n (mejores modelos por target):
- F1-Score promedio: **0.75 - 0.90**
- Accuracy: **> 0.80**
- Mejor algoritmo: **Random Forest**

Ver resultados detallados en: `data/08_reporting/tuning_summary.json`

---

## ğŸ”§ Feature Engineering

### Variables Creadas (80+ features)

#### Features Temporales:
- Variables lag (1, 3, 7, 14, 21 dÃ­as)
- Rolling statistics (medias mÃ³viles, desviaciones, min, max)
- Variables estacionales (componentes sin/cos)
- Tendencias y aceleraciÃ³n (derivadas temporales)
- Diferencias temporales

#### Features EpidemiolÃ³gicas:
- Tasas de letalidad diaria y acumulada
- Ratios de crecimiento temporal
- Ãndices de volatilidad
- Comparaciones regionales
- MÃ©tricas de cambio relativo

#### Transformaciones:
- **StandardScaler** para variables numÃ©ricas
- **MinMaxScaler** para variables cÃ­clicas
- **Label Encoding** para variables categÃ³ricas
- **Log transformation** para distribuciones asimÃ©tricas

---

## ğŸ“ Estructura del Proyecto
```
data_covid_ML/
â”œâ”€â”€ spaceflights/
â”‚   â”œâ”€â”€ .dvc/                           # ConfiguraciÃ³n DVC
â”‚   â”‚   â”œâ”€â”€ config                      # Remote storage config
â”‚   â”‚   â””â”€â”€ cache/                      # Cache local de DVC
â”‚   â”œâ”€â”€ conf/
â”‚   â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”‚   â”œâ”€â”€ catalog.yml             # DefiniciÃ³n de datasets
â”‚   â”‚   â”‚   â”œâ”€â”€ parameters.yml          # ParÃ¡metros ML
â”‚   â”‚   â”‚   â””â”€â”€ logging.yml             # ConfiguraciÃ³n logs
â”‚   â”‚   â””â”€â”€ local/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ 01_raw/                     # Datos originales (*.csv.dvc)
â”‚   â”‚   â”œâ”€â”€ 02_intermediate/            # Datos procesados intermedios
â”‚   â”‚   â”œâ”€â”€ 03_primary/                 # Datos limpios primarios
â”‚   â”‚   â”œâ”€â”€ 04_feature/                 # Features generados
â”‚   â”‚   â”œâ”€â”€ 05_model_input/             # Inputs para modelos
â”‚   â”‚   â”œâ”€â”€ 06_models/                  # Modelos entrenados (148MB)
â”‚   â”‚   â”œâ”€â”€ 07_model_output/            # MÃ©tricas y evaluaciÃ³n
â”‚   â”‚   â””â”€â”€ 08_reporting/               # Reportes y visualizaciones
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ 01_business_understanding.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_data_understanding.ipynb
â”‚   â”‚   â””â”€â”€ 03_data_preparation.ipynb
â”‚   â”œâ”€â”€ src/spaceflights/
â”‚   â”‚   â””â”€â”€ pipelines/
â”‚   â”‚       â”œâ”€â”€ data_processing/
â”‚   â”‚       â”‚   â”œâ”€â”€ nodes.py            # LÃ³gica de procesamiento
â”‚   â”‚       â”‚   â””â”€â”€ pipeline.py         # DefiniciÃ³n pipeline
â”‚   â”‚       â”œâ”€â”€ data_science/
â”‚   â”‚       â”‚   â”œâ”€â”€ nodes.py            # Entrenamiento modelos
â”‚   â”‚       â”‚   â””â”€â”€ pipeline.py
â”‚   â”‚       â””â”€â”€ reporting/
â”‚   â”‚           â”œâ”€â”€ nodes.py            # GeneraciÃ³n reportes
â”‚   â”‚           â””â”€â”€ pipeline.py
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ covid_ml_dag.py             # DAG de Airflow
â”‚   â”œâ”€â”€ docker-compose.airflow.yml      # ConfiguraciÃ³n Docker
â”‚   â”œâ”€â”€ dvc.yaml                        # Pipeline DVC
â”‚   â”œâ”€â”€ dvc.lock                        # Estado pipeline DVC
â”‚   â”œâ”€â”€ requirements.txt                # Dependencias Python
â”‚   â”œâ”€â”€ README.md                       # Este archivo
â”‚   â””â”€â”€ .gitignore                      # Archivos ignorados
```

---

## ğŸ“Š Resultados Principales

### Calidad de Datos
- **Score de calidad:** 92.0/100 (Excelente)
- **Completitud:** Mayor al 95% en variables clave
- **Cobertura temporal:** 727 dÃ­as consecutivos (2020-2022)
- **Ubicaciones procesadas:** 363 regiones/comunas

### Performance de Modelos
- **Modelos de regresiÃ³n:** RÂ² superior a 0.85
- **Modelos de clasificaciÃ³n:** F1-Score superior a 0.80
- **ValidaciÃ³n temporal:** Train/Val/Test split implementado
- **Feature importance:** Analizada y documentada

### Visualizaciones Generadas
1. **regression_comparison.png** - ComparaciÃ³n de RÂ² entre modelos
2. **classification_comparison.png** - ComparaciÃ³n de F1-Score
3. **summary_dashboard.png** - Dashboard con 4 paneles:
   - Top 8 modelos de regresiÃ³n
   - Top 8 modelos de clasificaciÃ³n
   - DistribuciÃ³n de RÂ² scores
   - DistribuciÃ³n de F1 scores

---

## ğŸ“¦ Dependencias del Sistema

### LibrerÃ­as Principales
```
kedro>=0.18.0
kedro-datasets>=3.0.0
kedro-airflow>=0.7.0
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0
plotly>=5.0.0
fastapi>=0.100.0
jupyter>=1.0.0
apache-airflow>=2.7.0
dvc>=3.0.0
```

Ver lista completa en `requirements.txt`

---

## ğŸ” Consideraciones TÃ©cnicas

### Reproducibilidad
- âœ… Control de versiones completo con Git
- âœ… Versionado de datos con DVC
- âœ… ParametrizaciÃ³n en archivos de configuraciÃ³n
- âœ… Seeds fijos para resultados reproducibles (random_state=42)
- âœ… DocumentaciÃ³n exhaustiva de decisiones
- âœ… Docker para ambiente aislado

### Buenas PrÃ¡cticas Implementadas
- âœ… Pipelines modulares y reutilizables (Kedro)
- âœ… SeparaciÃ³n clara entre datos raw y procesados
- âœ… Logging detallado de todos los procesos
- âœ… ValidaciÃ³n automÃ¡tica de calidad de datos
- âœ… Type hints en cÃ³digo Python
- âœ… Docstrings en funciones crÃ­ticas
- âœ… Git commits descriptivos y atÃ³micos

### Seguridad
- Credenciales en variables de entorno (no en cÃ³digo)
- `.gitignore` configurado correctamente
- Datos sensibles versionados con DVC (no en Git)

---

## ğŸ› Troubleshooting

### Error: "Memoria Agotada" en Docker
**SoluciÃ³n:** Aumenta memoria de WSL 2 a 8GB en `.wslconfig`

### Error: "DVC: output already specified"
**SoluciÃ³n:** Elimina archivos `.dvc` duplicados con `dvc remove`

### Error: "Kedro pipeline not found"
**SoluciÃ³n:** Verifica que estÃ¡s en el directorio `spaceflights/`

### Error: "Airflow DAG no aparece"
**SoluciÃ³n:** Verifica logs con `docker logs spaceflights-airflow-scheduler-1`

### Error: "GridSearchCV toma demasiado tiempo"
**SoluciÃ³n:** Reduce `cv_folds` en `parameters.yml` de 5 a 3

---

## ğŸ‘¥ Contribuciones

### MetodologÃ­a de Desarrollo
- Trabajo colaborativo con control de versiones (Git)
- Code review antes de integraciÃ³n
- DocumentaciÃ³n de decisiones tÃ©cnicas en commits
- Testing de funcionalidades crÃ­ticas

### Equipo
- **Claudia MurÃºa:** Data Engineering, MLOps (DVC, Airflow, Docker)
- **[Estudiante 2]:** Data Science, Feature Engineering, Modelado

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ desarrollado bajo licencia MIT para fines acadÃ©micos.

---

## ğŸ“ Contacto

- **Repositorio:** https://github.com/ClauMurua/data_covid_ML
- **DocumentaciÃ³n:** Ver notebooks en `/notebooks/`
- **Issues:** Reportar en el repositorio de GitHub

---

## ğŸ“ Referencias

- [Kedro Documentation](https://docs.kedro.org/)
- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [DVC Documentation](https://dvc.org/doc)
- [Scikit-learn Documentation](https://scikit-learn.org/)
- [CRISP-DM Methodology](https://www.datascience-pm.com/crisp-dm-2/)

---

**Ãšltima actualizaciÃ³n:** Octubre 2025  
**VersiÃ³n:** 1.0.0